<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <description>Minimalist blog.</description>
    <link>https://jaroslavurbann.github.io/blog/</link>
    <atom:link href="https://jaroslavurbann.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 16 Dec 2019 08:51:34 +0100</pubDate>
    <lastBuildDate>Mon, 16 Dec 2019 08:51:34 +0100</lastBuildDate>
    <generator>Jekyll v3.1.6</generator>
    
      <item>
        <title>Progtest Explained, Cutting Boards!</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/chopping_wood.gif&quot; alt=&quot;Get your axes out&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;problem-description&quot;&gt;Problem description&lt;/h2&gt;
&lt;p&gt;The task is to write a program that effectively cuts boards into smaller pieces for transportation.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;You get a board of a given size and your task is to use the lowest number of cuts possible to split it into smaller boards. These smaller boards need to satisfy a maximum area constraint given to you in the input. Additionally, the sizes of the final boards canâ€™t be in a ratio larger than 2:1 or smaller than 1:2.&lt;/p&gt;

&lt;h4 id=&quot;the-input--output-could-look-something-like-this&quot;&gt;The input &amp;amp; output could look something like this:&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/Selection_029.png&quot; alt=&quot;An example input&quot; height=&quot;400&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;p&gt;This task was designed to teach students recursion and so the bulk of the difficulty is hidden in the implementation itself, rather than the algorithm. With that, Iâ€™ll just quickly go through the algorithm:&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;1-realizing-that-there-are-no-algorithmic-shortcuts&quot;&gt;1) Realizing that there are no algorithmic shortcuts&lt;/h3&gt;
&lt;p&gt;After spending a few minutes with your pen and paper thinking about this problem, you should conclude that there is no general rule to be found in this particular problem. Youâ€™ll realize that for every pattern youâ€™ll find, you can find a counter-example. And if you canâ€™t, Progtest can.
Brute-force is the only option making this an algorithmically boring problem.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;2-a-simple-binary-tree-structure&quot;&gt;2) A simple binary tree structure&lt;/h3&gt;
&lt;p&gt;If a board is cut, it has to be split into 2 pieces. Each of these pieces is then a board in itself. Intuitively, this creates a binary tree-like structure where each node has 2 children like this:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;typedef struct BOARD {&lt;br /&gt;
int width, height;&lt;br /&gt;
BOARD *child1, *child2;&lt;br /&gt;
} board;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;3-the-recursive-function&quot;&gt;3) The recursive function&lt;/h3&gt;
&lt;p&gt;As I said, there isnâ€™t anything to this problem other than just understanding recursion. The whole program can be stripped down to one recursive function that could work something like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;int cutBoard ( board, max_area )&lt;br /&gt;
Â Â Â Â Â Â if ( area of the board &amp;lt; max_area &amp;amp;&amp;amp; 1:2 &amp;lt; ratio &amp;lt; 2:1)&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â return 0&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â number_of_cuts = INT_MAX&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â child1.width = width / 2&lt;br /&gt;
Â Â Â Â Â Â child2.width = width - child1.width&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â while ( child1.width &amp;gt; 0 )&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â cuts1 = cutBoard ( child1, max_area )&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â cuts2 = cutBoard ( child2, max_area )&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â if ( cuts1 + cuts2 + 1 &amp;lt; number_of_cuts )&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â number_of_cuts = cuts1 + cuts2 + 1&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â board.child1 = child1&lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â board.child2 = child2&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â Â Â Â Â Â Â child1.width - - &lt;br /&gt;
Â Â Â Â Â Â Â Â Â Â Â Â child2.width ++&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â ** do the same for height **&lt;/p&gt;

  &lt;p&gt;Â Â Â Â Â Â return number_of_cuts&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;4-a-simple-optimization&quot;&gt;4) A simple optimization&lt;/h3&gt;
&lt;p&gt;As this program would be incredibly slow by default, there &lt;strong&gt;needs&lt;/strong&gt; to be an optimization possible somehow.
The one I opted for is very simple. You just allocate a 2D array that is about the size of your input board. Each item in the array has 2 attributes: number_of_cuts and board.
Now you just cache all the values you get. This speeds things up immersely since you never need to recalculate anything.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Note that this optimization can be easily â€œbrokenâ€ just by inputting large values (for example Size: 1000 x 1000, Maximum Area: 500 000, requires just one cut but allocates a large amount of memory). But for this particular problem, it is sufficient.&lt;/p&gt;
</description>
        <pubDate>Mon, 16 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Cutting-boards!/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Cutting-boards!/</guid>
        
        
      </item>
    
      <item>
        <title>Progtest Explained, Autocomplete!</title>
        <description>
&lt;h2 id=&quot;problem-description&quot;&gt;Problem description&lt;/h2&gt;
&lt;p&gt;The task is to write a program that suggests common phrases based on a given text.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The input contains a set of phrases with usage frequencies and a set of queries. Your goal is to output up to 50 of the most common phrases that contain a given queried text. This should be done for every query.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The input &amp;amp; output could look something like this:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;Common phrases:&lt;/strong&gt;&lt;br /&gt;
30:Qui dolorem ipsum quia dolor sit amet&lt;br /&gt;
70:magnam aliquam quaerat&lt;br /&gt;
40:torquent per conubia nostra&lt;br /&gt;
90:tellus id magna elementum&lt;br /&gt;
&lt;strong&gt;Queries:&lt;/strong&gt;&lt;br /&gt;
agna&lt;br /&gt;
dolor&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;Found: 2&lt;/strong&gt;&lt;br /&gt;
tellus id magna elementum&lt;br /&gt;
magnam aliquam quaerat&lt;br /&gt;
&lt;strong&gt;Found: 1&lt;/strong&gt;&lt;br /&gt;
Qui dolorem ipsum quia dolor sit amet&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;
&lt;h3 id=&quot;1-a-few-considerable-approaches&quot;&gt;1) A few considerable approaches&lt;/h3&gt;

&lt;p&gt;Since this isnâ€™t a new problem by any means, there is a handful of approaches one can go with. Most notably, suffix trees and suffix arrays.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;A suffix tree can be constructed in O(n) time, where n denotes the number of characters in a phrase, and it can answer queries in O(m) time, where m denotes the number of characters in a query. As I see it, the two biggest disadvantages of suffix trees are memory consumption (which shouldnâ€™t be a problem as we were promptly informed in the original problem description) and secondly the complexity of creating the actual tree in O(n) time. It isnâ€™t by any means a trivial algorithm, especially for first-year students.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;A suffix array can be constructed in O(n * log n) at best, if you donâ€™t want to build a suffix tree in O(n) time beforehand. It can answer queries in O(m * log n) in the worst case. Suffix arrays are much easier to construct and take up less space. On the other hand, they do seem much slower, compared to suffix trees, when you look at the time complexities.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;2-why-didnt-it-work-when-i-implemented-one-of-these-algorithms&quot;&gt;2) Why didnâ€™t it work when I implemented one of these algorithms?&lt;/h3&gt;

&lt;p&gt;Well, we already established the importance of good time complexity in regards to the number of characters in a phrase and the number of characters in a query, but there is one more thing we left out to consider. Itâ€™s the number of phrases we have to search through.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;You might have thought about this and concluded that there is no reasonable way to include all phrases in one big suffix tree or one big suffix array because the worst-case time complexities would be insane. And youâ€™re right, but this is where you made the mistake of not considering the type of data you are being given by Progtest.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;3-clues-and-why-this-task-wouldnt-be-doable-without-them&quot;&gt;3) Clues, and why this task wouldnâ€™t be doable without them&lt;/h3&gt;
&lt;p&gt;The point to be taken here is, that with different types of input, the problemsâ€™ shape drastically changes.
The only description of the input for the bonus test went something like this: â€œThere will be many phrases, they will have many characters and there will be many queriesâ€.
What you need to realize is, that this doesnâ€™t tell you absolutely anything. The way you design your algorithm should change based on if youâ€™ll be getting 100 phrases that all look something like this:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;or if youâ€™ll be getting 10 000 phrases that all look something like this:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;abcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcdabcd&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and so onâ€¦&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;So in my opinion, the right move to make here is to take a clue for the bonus test and figure out what is the structure of the data youâ€™ll be getting.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;4-i-took-the-clue-what-now&quot;&gt;4) I took the clue, what now?&lt;/h3&gt;

&lt;p&gt;If your clue looks anything like mine, then you should be able to deduce that each phrase will have about 160 characters, that there can be up to about 5000 phrases and that each query will have about 45 characters. And most importantly, that these phrases will be reasonable, meaning that there wonâ€™t be any phrases with one repeating letter or any &lt;a href=&quot;https://en.wikipedia.org/wiki/Fibonacci_word&quot;&gt;fibonacci words&lt;/a&gt;, etc.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;Taking the figures above, you can easily calculate that with 160 and 45 characters, the difference between a suffix tree and a suffix array will most likely not be noticeable. Both in search and in construction. What will be noticeable is the &lt;strong&gt;possible multiply factor of 5000 for each query&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;5-so-whats-the-actual-algorithm-i-should-use&quot;&gt;5) So whatâ€™s the actual algorithm I should use?&lt;/h3&gt;

&lt;p&gt;I believe that you can use any reasonable algorithm as long as you optimize it in accordance with the Y-axis of the input data, meaning the number of phrases.
I ended up just creating one big suffix array for all the phrases altogether.&lt;/p&gt;
&lt;h4 id=&quot;heres-a-quick-summary-of-how-i-create-my-data-structure&quot;&gt;Hereâ€™s a quick summary of how I create my data structure:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;a)&lt;/strong&gt; Allocate an array for &lt;strong&gt;n * l&lt;/strong&gt; suffixes, where &lt;strong&gt;n&lt;/strong&gt; stands for the number of phrases and &lt;strong&gt;l&lt;/strong&gt; stands for the average length of a phrase&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;b)&lt;/strong&gt; Each suffix has these attributes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pointer to a phrase&lt;/li&gt;
  &lt;li&gt;Starting index (Where the suffix starts in the phrase)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;c)&lt;/strong&gt; Fill the array by iterating once through all the phrases&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;d)&lt;/strong&gt; Sort the array. Iâ€™m literally just using quicksort with no additional tricks. This could take up to about O{ (n * l^2^) * log (n * l^2^) } because we have n * l items and we could need to compare up to l characters when comparing two suffixes. But thatâ€™s only if all the phrases were composed of just one repeating letter. Since we know that isnâ€™t the case, quicksort will most likely need to compare only about the first 3-4 characters when comparing two suffixes. So the sorting should be reasonably fast.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h4 id=&quot;and-a-quick-summary-of-how-i-do-searches-in-my-suffix-array&quot;&gt;And a quick summary of how I do searches in my suffix array:&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;a)&lt;/strong&gt; Do a binary search on the suffix array and either return that no matches were found or return the position of a match.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;b)&lt;/strong&gt; Check for other matching suffixes around the one that was found and keep track of the phrases they belong to.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;c)&lt;/strong&gt; Take these phrases and print out up to 50 of the most common ones.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;And thatâ€™s it!&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Autocomplete!/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Autocomplete!/</guid>
        
        
      </item>
    
      <item>
        <title>Progtest Explained, Airplanes!</title>
        <description>&lt;h2 id=&quot;problem-description&quot;&gt;Problem description&lt;/h2&gt;
&lt;p&gt;The task is to write a program that outputs pairs of airplanes that are in danger of collision.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Each airplane (letâ€™s just call them points) has two coordinates [&lt;em&gt;x&lt;/em&gt;, &lt;em&gt;y&lt;/em&gt;] and a name. Your goal is to write out the shortest distance that can be found between these points and the names of the points that are separated by that distance.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The input &amp;amp; output could look something like this:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt;&lt;br /&gt;
[0, 0] Airplane1&lt;br /&gt;
[5, 5] Airplane2&lt;br /&gt;
[3, 0] Airplane3&lt;br /&gt;
[8, 5] Airplane4&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Output:&lt;/strong&gt;&lt;br /&gt;
Shortest distance: 3&lt;br /&gt;
Airplane1 - Airplane3&lt;br /&gt;
Airplane2 - Airplane4&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;
&lt;h3 id=&quot;1-designing-the-algorithm&quot;&gt;1) Designing the algorithm&lt;/h3&gt;

&lt;p&gt;For our solution, weâ€™ll be using a divide and conquer approach as described &lt;a href=&quot;https://en.wikipedia.org/wiki/Closest_pair_of_points_problem&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The quick summary goes like this:&lt;/p&gt;

&lt;p&gt;we take our points and split them in half:
&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/points1.png&quot; alt=&quot;points_divided_in_half&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;we calculate the shortest distance between 2 points in each half:
&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/points2.png&quot; alt=&quot;points_with_distance&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;we check if there is a pair of points in closer proximity to each other than the distance that we already found, on the edge of these 2 groups:
&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/points3.png&quot; alt=&quot;checking_the_strip&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;h3 id=&quot;2-things-to-note&quot;&gt;2) Things to note:&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;a)&lt;/strong&gt; The x coordinate at which we split our points is the x coordinate of a point at the (n/2)-th index when our points are sorted by x.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;b)&lt;/strong&gt; Calculating the shortest distance in the left and right group respectively is done recursively by the same algorithm until there are only around 3 - 4 points left and then we just do a brute force search.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;c)&lt;/strong&gt; Splitting the points and calculating the shortest distance in each group takes O(log N) time.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;d)&lt;/strong&gt; Calculating the shortest distance on the edges of our groups takes O(n) time, hereâ€™s why:&lt;/p&gt;

&lt;p&gt;When traversing the array of points that are located in the strip shown above (going from lowest to highest), the shortest distance can only occur between points that are separated by less than 8 points of each other when sorted by Y. Look at this visualization below:
&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/points4.png&quot; alt=&quot;strip_zoomed_in&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Imagine drawing a rectangle like this for every point you visit when traversing the array. You canâ€™t fit more than 8 points in it, because if you could, the distance &lt;em&gt;d&lt;/em&gt; would be smaller since it represents the shortest distance between 2 points on each side.&lt;/p&gt;

&lt;p&gt;So since weâ€™re checking only up to 8 points for each point, the complexity is O(n).&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;e)&lt;/strong&gt; Deriving from the observations above, at each step of our recursive algorithm, weâ€™ll need to have our points saved twice,  ordered by &lt;em&gt;x&lt;/em&gt; in one array (to split them into 2 groups) and ordered by &lt;em&gt;y&lt;/em&gt; in another array (to traverse the strip).&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;3-so-why-wont-this-work-out-of-the-box&quot;&gt;3) So, why wonâ€™t this work out of the box?&lt;/h3&gt;
&lt;p&gt;The reason is, that &lt;strong&gt;the algorithm above assumes unique &lt;em&gt;x&lt;/em&gt; coordinates&lt;/strong&gt; for each point. Meaning,  2 points canâ€™t share the same &lt;em&gt;x&lt;/em&gt; coordinate, which isnâ€™t the case in our problem.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;So how can this go wrong?&lt;/p&gt;

&lt;p&gt;Well, your sorting will most definitely fail. Imagine an input of points with &lt;em&gt;x&lt;/em&gt; values like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;1 2 3 4 5 5 5 5 5 5 5 5&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You pick the middle point (5), and split the array that is ordered by &lt;em&gt;Y&lt;/em&gt; into two groups: points with &lt;em&gt;X&lt;/em&gt; that is smaller than 5 and points with &lt;em&gt;X&lt;/em&gt; bigger or equal to 5 and get 2 groups:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;1 2 3 4&lt;br /&gt;
and&lt;br /&gt;
5 5 5 5 5 5 5 5&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And from this point onwards, you wonâ€™t ever split the fives apart meaning that your algorithm will never stop.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;4-how-can-we-fix-this-then&quot;&gt;4) How can we fix this then?&lt;/h3&gt;

&lt;p&gt;To fix this, we are going to choose more than one â€œmiddle pointâ€ when splitting our points into 2 groups and we wonâ€™t be including them in neither of these groups. More precisely, we are going to choose all points that have the same &lt;em&gt;X&lt;/em&gt;  as the point at the  (n/2)-th index, as our middle points.&lt;/p&gt;

&lt;p&gt;After that, we will calculate the shortest distance in each group and then traverse the strip with our middle points included.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h3 id=&quot;5-it-still-doesnt-work-whats-wrong&quot;&gt;5) It still doesnâ€™t work, whatâ€™s wrong?&lt;/h3&gt;

&lt;p&gt;The problem that is most likely arising here is, that the 8 point rule described above doesnâ€™t hold anymore. If we get an input with points that have the same &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;Y&lt;/em&gt; and they end up as our middle points, then there can be an infinite amount of points in our rectangle that is visualized above.&lt;/p&gt;

&lt;p&gt;To mitigate this, we just simply allocate another dynamic array to hold the indexes of all points that are less than &lt;em&gt;d&lt;/em&gt; (the shortest distance that we found so far) below our current point, when we traverse the split.&lt;/p&gt;

&lt;p&gt;With all that, our algorithm should now be modified enough to work on this particular problem.&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Dec 2019 00:00:00 +0100</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Airplanes!/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Airplanes!/</guid>
        
        
      </item>
    
      <item>
        <title>Progtest Explained, Water Tanks!</title>
        <description>&lt;h2 id=&quot;problem-description&quot;&gt;Problem description&lt;/h2&gt;
&lt;p&gt;The task is to write a program that can compute the altitude of the water surface in a system of water tanks.&lt;/p&gt;

&lt;p&gt;Letâ€™s say that there is a water company that manages water tanks. Every water tank has a block-like shape and is connected to every other water tank with tubes of zero volume (to ease our calculations). The situation is as given:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/water_tanks.png&quot; alt=&quot;Image from the original Progtest problem&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;em&gt;Image from the original Progtest problem&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The input is a set of n (n &amp;lt;= 200 000) water tanks defined as Alt H W D. Alt is the altitude of the bottom of a given water tank, H is the height, W is the width and D is the depth.&lt;/p&gt;

&lt;p&gt;Next comes a sequence of queries with different volumes of water. &lt;strong&gt;The task is to compute the altitude of the water surface&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;h3 id=&quot;1-cultivating-our-data&quot;&gt;1) Cultivating our data&lt;/h3&gt;

&lt;p&gt;Firstly, the width and depth of a water tank can be multiplied and combined into a single variable containing the area of a base of a given water tank.&lt;/p&gt;

&lt;p&gt;Secondly, the altitude and height of a water tank can also be combined into (semantically) one variable, the altitude of the lower base (Alt) and altitude of the upper base (Alt + H).&lt;/p&gt;

&lt;p&gt;We now have &lt;strong&gt;2 types of variables:&lt;/strong&gt; altitudes and areas.&lt;/p&gt;

&lt;h3 id=&quot;2-the-imagination-bit&quot;&gt;2) The imagination bit&lt;/h3&gt;

&lt;p&gt;Now imagine going from the lowest point of our water tank system to the highest point of our water tank system. The total water area would change based on our water tanks being â€œaddedâ€ and â€œremovedâ€ as we go.&lt;/p&gt;

&lt;p&gt;We should try and represent that with our data.&lt;/p&gt;

&lt;h3 id=&quot;3-creating-our-dataset&quot;&gt;3) Creating our dataset&lt;/h3&gt;

&lt;p&gt;Notice that our input data can be easily transformed into 2n objects with the following two attributes: area_added and altitude. Letâ€™s call these objects thresholds and look at the example below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/thresholds.png&quot; alt=&quot;Visualizing Thresholds&quot; /&gt;
&lt;em&gt;Note the minuses in area_added in the top thresholds.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;If we save our thresholds in an array and sort them by altitude, we can imagine our area_added attributes looking like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/arr1.png&quot; alt=&quot;Our array&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-transformations-transformations&quot;&gt;4) Transformations, transformations&lt;/h3&gt;

&lt;p&gt;If we iterate over the array once and add up our surfaces, we can visualize the state of our array like this, aka &lt;strong&gt;the total surface at each altitude&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/arr2.png&quot; alt=&quot;Our array after the first transformation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If we now take an item from the array and multiply its area with (altitude of the next item - our itemsâ€™ altitude), &lt;strong&gt;we get the total volume between 2 altitudes&lt;/strong&gt;. Since we want to query the global total volume, we just need to iterate the array once more and take these intermediate volumes and add them all together into an array thatâ€™s telling us the cumulative volume of our water tank system.&lt;/p&gt;

&lt;p&gt;After these transformations, we get an array with &lt;strong&gt;the cumulative volume of our water tank system.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Remember, our now array stores 2 types of information at each index, the altitude and the total volume of our system up to that altitude.&lt;/p&gt;

&lt;p&gt;So we can now perform a simple binary search on our array to get upper and lower altitude boundaries for our volume and calculate the real altitude with:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.codecogs.com/eqnedit.php?latex=\large&amp;space;\\&amp;space;A_L&amp;space;=&amp;space;\text{Altitude&amp;space;of&amp;space;the&amp;space;lower&amp;space;boundary}\\&amp;space;A_U&amp;space;=&amp;space;\text{Altitude&amp;space;of&amp;space;the&amp;space;upper&amp;space;boundary}\\&amp;space;V_Q&amp;space;=&amp;space;\text{Queried&amp;space;volume}\\&amp;space;V_L&amp;space;=&amp;space;\text{Volume&amp;space;of&amp;space;the&amp;space;lower&amp;space;boundry}\\&amp;space;V_U&amp;space;=&amp;space;\text{Volume&amp;space;of&amp;space;the&amp;space;upper&amp;space;boundry}\\&amp;space;\\&amp;space;V&amp;space;=&amp;space;A_L&amp;space;&amp;plus;&amp;space;(A_U&amp;space;&amp;plus;&amp;space;A_L)&amp;space;\cdot&amp;space;\tfrac{V_Q&amp;space;-&amp;space;V_L}{V_U&amp;space;-&amp;space;V_L}\\&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://latex.codecogs.com/gif.latex?\large&amp;space;\\&amp;space;A_L&amp;space;=&amp;space;\text{Altitude&amp;space;of&amp;space;the&amp;space;lower&amp;space;boundary}\\&amp;space;A_U&amp;space;=&amp;space;\text{Altitude&amp;space;of&amp;space;the&amp;space;upper&amp;space;boundary}\\&amp;space;V_Q&amp;space;=&amp;space;\text{Queried&amp;space;volume}\\&amp;space;V_L&amp;space;=&amp;space;\text{Volume&amp;space;of&amp;space;the&amp;space;lower&amp;space;boundry}\\&amp;space;V_U&amp;space;=&amp;space;\text{Volume&amp;space;of&amp;space;the&amp;space;upper&amp;space;boundry}\\&amp;space;\\&amp;space;V&amp;space;=&amp;space;A_L&amp;space;&amp;plus;&amp;space;(A_U&amp;space;&amp;plus;&amp;space;A_L)&amp;space;\cdot&amp;space;\tfrac{V_Q&amp;space;-&amp;space;V_L}{V_U&amp;space;-&amp;space;V_L}\\&quot; title=&quot;\large \\ A_L = \text{Altitude of the lower boundary}\\ A_U = \text{Altitude of the upper boundary}\\ V_Q = \text{Queried volume}\\ V_L = \text{Volume of the lower boundry}\\ V_U = \text{Volume of the upper boundry}\\ \\ V = A_L + (A_U + A_L) \cdot \tfrac{V_Q - V_L}{V_U - V_L}\\&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Nov 2019 00:00:00 +0100</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Water-tanks!/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Progtest-explained,-Water-tanks!/</guid>
        
        
      </item>
    
      <item>
        <title>Symposium, Book ğŸ‘ Review ğŸ‘</title>
        <description>&lt;p&gt;I read the whole book and I liked it, but I felt like I needed something more logic-based after I finished reading it.&lt;/p&gt;

&lt;h2 id=&quot;random-note&quot;&gt;Random note&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;I was surprised how bisexual everyone was. When some of them talked about the concept of love, they were talking about the homosexual relationship between an older and a younger man.&lt;/li&gt;
  &lt;li&gt;One person even said that love of boys is a more noble kind of love because they are born smarter and overall better.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;h2 id=&quot;notes-on-the-actual-point-of-the-book&quot;&gt;Notes on the actual point of the book:&lt;/h2&gt;

&lt;p&gt;Every speaker took a turn and shared their take on Eros with others, here are some points they made that I still remember:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There is an upper and a lower kind of love
    &lt;ul&gt;
      &lt;li&gt;lower love is the love of things that change: money, appearance, etc.&lt;/li&gt;
      &lt;li&gt;upper love is the love of the truth, which doesnâ€™t change&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;When people do things for love, even the most atypical kind of behavior suddenly becomes acceptable&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;One speaker had a theory that people originally had 2 heads, arms, legs .. and that they were split into two and now we search the world for our soulmate from whom we were separated like this&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Socrates said that people wish for things that they donâ€™t possess, which he very clearly explains and it makes sense. But then he transfers that principle onto love without any explanation and claims that, therefore, love things that they donâ€™t have. I didnâ€™t see why that should be the case when I was reading the book, but it made more sense when I heard that ancient greek had the same word for love and want.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The idea that lovers should make each other the best person they can be also appeared in this book and I like it a lot.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 20 Oct 2019 00:00:00 +0200</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Symposium,-Book-Review/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Symposium,-Book-Review/</guid>
        
        
      </item>
    
      <item>
        <title>Ai Superpowers, Book ğŸ‘ Review ğŸ‘</title>
        <description>&lt;h2 id=&quot;random-notes-on-a-book-by-kai-fu-lee&quot;&gt;Random notes on a book by Kai-fu Lee&lt;/h2&gt;

&lt;p&gt;Its the first book on AI I ever read. Unfortunately, I stopped in about 3/4 of the book, I felt like it was getting repetitive.&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I liked the authorsâ€™ notes on China, itâ€™s a topic Iâ€™m very interested in. Here are some thoughts that I havenâ€™t heard before:
    &lt;ul&gt;
      &lt;li&gt;Mobile apps are done differently in western countries - many apps for many different things instead of one big one for everything.&lt;/li&gt;
      &lt;li&gt;Western companies routinely fail when investing money and resources into the Chinese market - they donâ€™t adapt to different needs and habits of the Chinese.&lt;/li&gt;
      &lt;li&gt;Chinese companies that rip off western brands (in the internet sphere) are not just lazy copycats, they are willing to adapt their product which makes them win out over the original.&lt;/li&gt;
      &lt;li&gt;Chinasâ€™ copycats competing against each other gave birth to great Chinese entrepreneurs.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;And some notes on AIsâ€™ future (and China again):
    &lt;ul&gt;
      &lt;li&gt;The age of implementation arrived and AI research might slow down.&lt;/li&gt;
      &lt;li&gt;The amount and quality of data will be a big factor and China has a centralized mobile application (WeChat) that produces enormous amounts of data, and that also reaches much further into the real life of itsâ€™ own users more than any other western app.&lt;/li&gt;
      &lt;li&gt;I never realized how much of the current AI is just on the internet and not in real life.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Some topics from the latter part of the book:
    &lt;ul&gt;
      &lt;li&gt;The potential loss of jobs and existential crisis.
        &lt;ul&gt;
          &lt;li&gt;These topics seemed quite theoretical and were relying on a lot of what-ifs, so decided to skip them. Might revisit them later.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 10 Sep 2019 00:00:00 +0200</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/AI-Superpowers,-Book-Review/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/AI-Superpowers,-Book-Review/</guid>
        
        
      </item>
    
      <item>
        <title>Try Stopping Early</title>
        <description>&lt;p&gt;If youâ€™re a competitive person, then you like spending your time effectively.
The natural time spent distribution of any sort of endeavor looks something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JaroslavUrbann/blog/master/assets/images/time_graph.png&quot; alt=&quot;The typical distribution of your interest and time spent&quot; /&gt;&lt;/p&gt;

&lt;p&gt;An old Czech proverb says that you should â€œend at the height of thingsâ€. Itâ€™s not something many people do, simply because their interest still brings them pleasure and they donâ€™t want to or donâ€™t have the will power, to end things abruptly. Quite often you see people who stopped giving their fullest to a sport, yet they still hang around for a few years, missing workouts here and there and seemingly just doing everything out of habit, with no real goal in mind. Or people who are now adults and still come back to videogames, but always ever less so often than before, until they eventually stop altogether. Or people who still hang on to their old partners, even though they know that their relationship is dying down and wonâ€™t stand the test of time in the ensuing few years. If you feel like youâ€™re reaching the right slope of the graph, man up, overcome nostalgia and completely cut it out of your life and youâ€™ll be rewarded by only remembering the good times.&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Aug 2019 00:00:00 +0200</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Try-stopping-early/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Try-stopping-early/</guid>
        
        
      </item>
    
      <item>
        <title>Overcomming Procrastination</title>
        <description>&lt;p&gt;The key is in setting a specific goal. If you wish to be wealthy, then thatâ€™s a great start to becoming wealthy, but itâ€™s not a great goal. &lt;strong&gt;Great goals should make you do things to achieve them&lt;/strong&gt;. When wishing to be wealthy, a great goal would be to, for example, launch a startup. Itâ€™s quite simple to see what things a startup CEO should know/do. They should study basic economics, follow current trends, learn how to be likable, read relevant books, etc.. And since you already have these things in your head, youâ€™ll be inclined to pick a few that you like and start studying. It comes down to being able to see the specific things that youâ€™re missing and youâ€™ll automatically start filling the gaps to get closer to your goal.&lt;/p&gt;
</description>
        <pubDate>Sun, 21 Jul 2019 00:00:00 +0200</pubDate>
        <link>https://jaroslavurbann.github.io/blog/2019/Overcomming-procrastination/</link>
        <guid isPermaLink="true">https://jaroslavurbann.github.io/blog/2019/Overcomming-procrastination/</guid>
        
        
      </item>
    
  </channel>
</rss>
